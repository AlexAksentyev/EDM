\documentclass{article}
\usepackage[left=1cm,top=1cm,right=1cm,bottom=1.5cm]{geometry}
\setlength{\parindent}{0pt}
\usepackage{parskip}

\usepackage{mathtools}

\usepackage{xparse}
\usepackage{xfrac}

\DeclareDocumentCommand{\bkt}{sm}{\IfBooleanTF{#1}{\left[ #2 \right]}{\left(#2\right)}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\pars}{\boldsymbol{\theta}}
\DeclareDocumentCommand{\Xpct}{mo}{\mathrm{E}\bkt*{#1\IfNoValueTF{#2}{}{|~ #2}}}
\DeclareDocumentCommand{\XpctO}{m}{\Xpct{#1}[\pars_0]}

\DeclareDocumentCommand{\mupp}{s}{\mu'_\phi\IfBooleanTF{#1}{}{(t_i)}}
\DeclareDocumentCommand{\mudpp}{s}{\mu''_{\phi^2}\IfBooleanTF{#1}{}{(t_i)}}


\begin{document}

The probability of observing  the value $y_i \equiv y(t_i)$ when the expectation value is $\mu(t_i)$ and the error is gaussian is
\begin{align*}
	f(y_i|\pars) &= \frac{1}{\sqrt{2\pi\nu}}\exp\bkt{-\frac12\frac{(y_i - \mu(t_i))^2}{\nu}}, \\
	\pars 		  &= (\nu,\omega,\phi),\\
	\mu(t_i) 	  &= N_0\bkt{1 + P\sin(\omega t_i + \phi)}.
\end{align*}

The likelihood of observing a set of observations $\y = (y_1,\dots, y_K)$, under the i.i.d. assumption, is the product of propabilities taken as a function of the parameters:
\begin{align*}
	\mathcal{L}(\pars|\y) &= \prod_i f(y_i|\pars),
\shortintertext{and the log-likelihood}
	\ell(\pars|\y) &= -\frac{K}{2}\log2\pi - \frac{K}{2}\log\nu - \frac{1}{2\nu}\sum_i\epsilon_i^2,
	~ \epsilon_i = y_i- \mu(t_i).
\end{align*}
The usual assumptions for the error term are zero expectation and strict exogeneity
\begin{align*}
	\XpctO{\epsilon_i} &= \XpctO{t_i\epsilon_i} = 0,
\intertext{and the relations between the mean's derivatives are}
	\mu'_\phi	&= N_0P\cos(\omega t + \phi), \\
	\mu'_\omega &= t\cdot\mu'_\phi, \epsilon'_\xi = -\mu'_\xi.
\end{align*}

The log-likelihood derivatives:
\begin{align*}
\ell'_\nu 		&= -\frac{K}{2\nu} + \frac{1}{2\nu^2}\sum_i\epsilon_i^2;  & \\
\ell'_\omega 	&= \frac1\nu\sum_i\mupp t_i\epsilon_i;  & \\
\ell'_\phi		&= \frac1\nu \sum_i \mupp\epsilon_i; & \\
%
\ell''_{\nu^2}		&= \frac{K}{2\nu^2} - \frac{1}{\nu^3}\sum_i\epsilon_i^2, 
	&-\XpctO{\ell''_{\nu^2}} = \frac{K}{2\nu^2} - \frac{1}{\nu^3}\sum_i\nu = \frac{K}{2\nu^2};\\
\ell''_{\nu\omega}	&= -\frac{1}{\nu^2}\sum_i\mupp t_i\epsilon_i, 
	&-\XpctO{\ell''_{\nu\omega}} = \frac{1}{\nu^2}\sum_i\mupp\XpctO{t_i\epsilon_i} = 0;\\
\ell''_{\nu\phi}	&= -\frac{1}{\nu^2}\sum_i\mupp \epsilon_i, 
	&-\XpctO{\ell''_{\nu\phi}} = \frac{1}{\nu^2}\sum_i\mupp\XpctO{\epsilon_i} = 0; \\
\ell''_{\phi^2}		&= \frac1\nu\sum_i\bkt{\mudpp \epsilon_i - \bkt{\mupp}^2}, 
	&-\XpctO{\ell''_{\phi^2}} = \frac1\nu\sum_i\bkt{\bkt{\mupp}^2 - \mudpp\XpctO{\epsilon_i}} = \frac1\nu\sum_i\bkt{\mupp}^2;\\
\ell''_{\phi\omega}	&= \frac1\nu\sum_i\bkt{\mudpp t_i\epsilon_i - \bkt{\mupp}^2t_i}, 
	&-\XpctO{\ell''_{\phi\omega}} = \frac1\nu\sum_i\bkt{t_i\bkt{\mupp}^2 - \mudpp\XpctO{t_i\epsilon_i}} = \frac1\nu\sum_i t_i\bkt{\mupp}^2;\\
\ell''_{\omega^2}	&= \frac1\nu\sum_i\bkt{\mudpp t_i^2\epsilon_i - \bkt{\mupp t_i}^2},
	& -\XpctO{\ell''_{\omega^2}} = \frac1\nu\sum_i\bkt{\bkt{t_i\mupp}^2 - \mudpp\XpctO{t_i^2\epsilon_i}} = \frac1\nu\sum_i\bkt{t_i\mupp}^2.
\end{align*}

\section{Variances}

The Fisher matrix
\[
	I(\pars_0) = \begin{pmatrix}
	\sfrac{K}{2\nu} & 0 								& 0 \\
	0 				& \sfrac1\nu\sum\bkt{t_i\mupp}^2	& \sfrac1\nu\sum t_i\bkt{\mupp}^2 \\
	0				& \sfrac1\nu\sum t_i\bkt{\mupp}^2	&\sfrac1\nu\sum\bkt{\mupp}^2
	\end{pmatrix}.
\]
The determinant
\newcommand{\STM}{\Omega}
\[
	|I(\pars_0)| = \frac{K}{2\nu^4}\underbrace{\bkt{\sum\bkt{t_i\mupp}^2\sum\bkt{\mupp}^2 - \bkt{\sum t_i\bkt{\mupp}^2}^2}}_{\STM}.
\]
The variance-covariance matrix
\[
vcov = \begin{pmatrix}
	2\sfrac{\nu^2}{K}& 0									& 0				\\
	0				&\nu\frac{\sum\bkt{\mupp}^2}{\STM}		&\nu\frac{\sum t_i\bkt{\mupp}^2}{\STM}\\
	0				&\nu\frac{\sum t_i\bkt{\mupp}^2}{\STM}	&\nu\frac{\sum\bkt{t_i\mupp}^2}{\STM}
\end{pmatrix}.
\]

Variance of the frequency estimate
\[
	var(\hat{\omega}) = \nu\frac{\sum\bkt{\mupp}^2}{\sum\bkt{t_i\mupp}^2\sum\bkt{\mupp}^2 - \bkt{\sum t_i\bkt{\mupp}^2}^2}.
\]

\newcommand{\avg}[1]{\langle #1\rangle}
\paragraph{Cross-check.} Let $\mu(t_i) = \phi + \omega t_i$. In that case $\mupp = 1$, $\mu'_\omega(t_i) = t_i = t_i\cdot\mupp$, the determinant of the Fisher matrix simplifies to 
\begin{align*}
	|I(\pars_0)| &= \frac{K}{2\nu^4}\bkt{K\sum_i t_i^2 - \bkt{\sum t_i}^2} \\
				 &= \frac{K^3}{2\nu^4}\bkt{\frac1K\sum t_i^2 - \avg{t}^2} \\
				 &= \frac{K}{2\nu^4}\cdot\underbrace{K\sum\bkt{t_i - \avg{t}}^2}_{\STM}
\end{align*}
\newcommand{\SSX}{\sum\bkt{t_i - \avg{t}}^2}
and the variance-covariance matrix becomes
\[
vcov = \begin{pmatrix}
	2\sfrac{\nu^2}{K}& 0									& 0				\\
	0				&\frac{\nu}{\SSX}		&\nu\frac{\sum t_i}{K\SSX}\\
	0				&\nu\frac{\sum t_i}{K\SSX}	&\nu\frac{\sum t_i^2}{K\SSX}
\end{pmatrix},
\]
with the well-known expression for the slope variance
\[
	var(\hat\omega) = \frac{\nu}{\SSX}.
\]

\newcommand{\M}{\underline{\mathrm{M}}}
\newcommand{\T}{\underline{\mathrm{T}}}
\newcommand{\diag}[1]{\mathcal{D}_{#1}}
\newcommand{\diagM}{\diag{\mu}}
In matrix form, the frequency variance is written as
\begin{align*}
var(\hat\omega) &= \nu\frac{\M'\M}{\bkt{\T'\diagM\T}\bkt{\M'\M} - \bkt{\T'\diagM\M}^2}, 
\shortintertext{with}
\T &= \bkt{t_0,\dots, t_{K-1}}', ~ \M = \bkt{\mupp*(t_0),\dots,\mupp*(t_{K-1})}', \\
\diagM &= \begin{pmatrix}
	\mupp*(t_0) & 0				& \cdots & 0 \\
	0			& \mupp*(t_1)	& \cdots & 0 \\
	\vdots		& \cdots		&\ddots	 & \vdots \\
	0			& 0				&\cdots  & \mupp*(t_{K-1})
\end{pmatrix}.
\end{align*}

\section{Estimates}


\end{document}
